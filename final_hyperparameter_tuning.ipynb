{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.22.0\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-139721\n",
      "Azure region: southcentralus\n",
      "Subscription id: 9b72f9e6-56c5-4c16-991b-19c652994860\n",
      "Resource group: aml-quickstarts-139721\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-02T17:33:18.607000+00:00', 'errors': None, 'creationTime': '2021-03-02T17:11:16.631284+00:00', 'modifiedTime': '2021-03-02T17:11:31.985785+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"compute-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# can poll for a minimum number of nodes and for a specific timeout. \n",
    "# if no min node count is provided it uses the scale settings for the cluster\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "project_folder = './capstone-project'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./capstone-project/train.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('train.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'House_Price_Predication'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore,Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# subscription_id = '9b72f9e6-56c5-4c16-991b-19c652994860'\n",
    "# resource_group = 'aml-quickstarts-139721'\n",
    "# workspace_name = 'quick-starts-ws-139721'\n",
    "\n",
    "# workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "ws = Workspace.from_config()\n",
    "#ws\n",
    "\n",
    "# get the name of defult Datastore associated with the workspace.\n",
    "default_dsname = ws.get_default_datastore().name\n",
    "default_ds = ws.get_default_datastore()\n",
    "print('default Datastore = ', default_dsname)\n",
    "\n",
    "#Upload the files in default datastore\n",
    "default_ds.upload_files(files=['./house-price-train-data.csv']\n",
    "                        ,target_path='capstoneproject/'\n",
    "                        ,overwrite=True, show_progress=True)\n",
    "\n",
    "flower_data_ref = default_ds.path('capstoneproject').as_download('ex_capstoneproject')\n",
    "print('reference_path = ',flower_data_ref)\n",
    "\n",
    "\n",
    "# Creating tabular dataset from files in datastore.\n",
    "tab_dataset = Dataset.Tabular.from_delimited_files(path=(default_ds,'/capstoneproject/*.csv'))\n",
    "#tab_dataset.take(10).to_pandas_dataframe()\n",
    "\n",
    "# register tabular dataset in Workspace\n",
    "tab_dataset = tab_dataset.register(workspace=ws, \n",
    "                                   name='house price train data', \n",
    "                                   description='Kaggle house price Dataset in tabular format', \n",
    "                                   tags={'format':'CSV'}, create_new_version=True)\n",
    "\n",
    "# Get the data Using Dataset name which is registered.\n",
    "dataset = Dataset.get_by_name(ws, name='house price train data')\n",
    "ds=dataset.to_pandas_dataframe()\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default Datastore =  capstoneproject\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./house-price-test-data.csv\n",
      "Uploaded ./house-price-test-data.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      "reference_path =  $AZUREML_DATAREFERENCE_ac542aeaeff545f4b36cb44a0fa40c6e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore,Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core.run import Run\n",
    "\n",
    "# subscription_id = '9b72f9e6-56c5-4c16-991b-19c652994860'\n",
    "# resource_group = 'aml-quickstarts-139721'\n",
    "# workspace_name = 'quick-starts-ws-139721'\n",
    "\n",
    "# workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "ws = Workspace.from_config()\n",
    "#ws\n",
    "\n",
    "default_dsname = ws.get_default_datastore().name\n",
    "default_ds = ws.get_default_datastore()\n",
    "print('default Datastore = ', default_dsname)\n",
    "\n",
    "#Upload the test files in default datastore\n",
    "default_ds.upload_files(files=['./house-price-test-data.csv']\n",
    "                        ,target_path='capstoneproject/'\n",
    "                        ,overwrite=True, show_progress=True)\n",
    "\n",
    "flower_data_ref = default_ds.path('capstoneproject').as_download('ex_capstoneproject')\n",
    "print('reference_path = ',flower_data_ref)\n",
    "\n",
    "\n",
    "# Creating tabular dataset from files in datastore.\n",
    "tab_dataset = Dataset.Tabular.from_delimited_files(path=(default_ds,'/capstoneproject/house-price-test-data.csv'))\n",
    "#tab_dataset.take(10).to_pandas_dataframe()\n",
    "\n",
    "# register tabular dataset in Workspace\n",
    "tab_dataset = tab_dataset.register(workspace=ws, \n",
    "                                   name='house price test data', \n",
    "                                   description='Kaggle house price test Dataset in tabular format', \n",
    "                                   tags={'format':'CSV'}, create_new_version=True)\n",
    "\n",
    "# Get the data Using Dataset name which is registered.\n",
    "dataset = Dataset.get_by_name(ws, name='house price test data')\n",
    "ds=dataset.to_pandas_dataframe()\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an environment\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "# Conda environment specification. The dependencies defined in this file will\n",
    "# be automatically provisioned for runs with userManagedDependencies=False.\n",
    "\n",
    "# Details about the Conda environment file format:\n",
    "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
    "\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-train-automl-runtime==1.21.0\n",
    "  - inference-schema\n",
    "  - azureml-interpret==1.21.0\n",
    "  - azureml-defaults==1.21.0\n",
    "- numpy>=1.16.0,<1.19.0\n",
    "- pandas==0.25.1\n",
    "- scikit-learn==0.22.1\n",
    "- xgboost<=1.3.3\n",
    "- psutil>=5.2.2,<6.0.0\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.from_conda_specification(name = 'capstone-project-env', file_path = './conda_dependencies.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory=project_folder,\n",
    "                      script='train.py',\n",
    "                      arguments=['--max_depth', '5'\n",
    "                                 ,'--learning_rate',  0.1\n",
    "                                 ,'--colsample_bytree',0.3\n",
    "                                 ,'--alpha',10\n",
    "                                 ,'--n_estimators',10],\n",
    "                      compute_target=compute_target,\n",
    "                      environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor The Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035527e076a64eb0bca91542edae00d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/House_Price_Predication/runs/House_Price_Predication_1614714913_987952f3?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-139721/workspaces/quick-starts-ws-139721\", \"run_id\": \"House_Price_Predication_1614714913_987952f3\", \"run_properties\": {\"run_id\": \"House_Price_Predication_1614714913_987952f3\", \"created_utc\": \"2021-03-02T19:55:14.896475Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"e8d326c7-f0fd-4b13-adca-699a2bb3fdef\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_6521a804b8d3f084e20b6437dc8a280e059d4046bf48dab17670cea1d85aa978_d.txt\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614714913_987952f3/azureml-logs/55_azureml-execution-tvmps_6521a804b8d3f084e20b6437dc8a280e059d4046bf48dab17670cea1d85aa978_d.txt?sv=2019-02-02&sr=b&sig=KNe0sg%2BqZsDGi5CjyRJ30WjS2%2FrZHXjfF3HDQJABy4o%3D&st=2021-03-02T19%3A50%3A03Z&se=2021-03-03T04%3A00%3A03Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/55_azureml-execution-tvmps_6521a804b8d3f084e20b6437dc8a280e059d4046bf48dab17670cea1d85aa978_d.txt\"]], \"run_duration\": \"0:07:19\", \"run_number\": \"15\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2021-03-02T19:59:53Z Starting output-watcher...\\n2021-03-02T19:59:53Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\\n2021-03-02T19:59:53Z Executing 'Copy ACR Details file' on 10.0.0.4\\n2021-03-02T19:59:53Z Copy ACR Details file succeeded on 10.0.0.4. Output: \\n>>>   \\n>>>   \\nLogin Succeeded\\nUsing default tag: latest\\nlatest: Pulling from azureml/azureml_17b7ef3d4500f7b1271481f84603f948\\nbe8ec4e48d7f: Pulling fs layer\\n33b8b485aff0: Pulling fs layer\\nd887158cc58c: Pulling fs layer\\n05895bb28c18: Pulling fs layer\\nbaf7ab26f516: Pulling fs layer\\n181182e3c9cf: Pulling fs layer\\nd584ef274e55: Pulling fs layer\\nc445dda55407: Pulling fs layer\\n699b75ff4717: Pulling fs layer\\nb177109c9d16: Pulling fs layer\\n59cea07bb66c: Pulling fs layer\\nd54d011de0e3: Pulling fs layer\\n9e568eb651a5: Pulling fs layer\\nd624e6e7775d: Pulling fs layer\\n039697e10c84: Pulling fs layer\\ncf1f21b548a5: Pulling fs layer\\n0fd8b2b70fed: Pulling fs layer\\n43bfd8262e45: Pulling fs layer\\nb6b8ce44d43b: Pulling fs layer\\nb3ad9472f087: Pulling fs layer\\n1fba209e6565: Pulling fs layer\\n05895bb28c18: Waiting\\nbaf7ab26f516: Waiting\\n181182e3c9cf: Waiting\\nd584ef274e55: Waiting\\nc445dda55407: Waiting\\n699b75ff4717: Waiting\\nb177109c9d16: Waiting\\n59cea07bb66c: Waiting\\nd54d011de0e3: Waiting\\n9e568eb651a5: Waiting\\nd624e6e7775d: Waiting\\n039697e10c84: Waiting\\ncf1f21b548a5: Waiting\\n0fd8b2b70fed: Waiting\\n43bfd8262e45: Waiting\\nb6b8ce44d43b: Waiting\\nb3ad9472f087: Waiting\\n1fba209e6565: Waiting\\nd887158cc58c: Verifying Checksum\\nd887158cc58c: Download complete\\n33b8b485aff0: Verifying Checksum\\n33b8b485aff0: Download complete\\n05895bb28c18: Verifying Checksum\\n05895bb28c18: Download complete\\nbe8ec4e48d7f: Verifying Checksum\\nbe8ec4e48d7f: Download complete\\n181182e3c9cf: Verifying Checksum\\n181182e3c9cf: Download complete\\nd584ef274e55: Verifying Checksum\\nd584ef274e55: Download complete\\nbaf7ab26f516: Verifying Checksum\\nbaf7ab26f516: Download complete\\nc445dda55407: Verifying Checksum\\nc445dda55407: Download complete\\n59cea07bb66c: Verifying Checksum\\n59cea07bb66c: Download complete\\nb177109c9d16: Verifying Checksum\\nb177109c9d16: Download complete\\nd54d011de0e3: Verifying Checksum\\nd54d011de0e3: Download complete\\n9e568eb651a5: Verifying Checksum\\n9e568eb651a5: Download complete\\nd624e6e7775d: Verifying Checksum\\nd624e6e7775d: Download complete\\n699b75ff4717: Verifying Checksum\\n699b75ff4717: Download complete\\ncf1f21b548a5: Verifying Checksum\\ncf1f21b548a5: Download complete\\n039697e10c84: Verifying Checksum\\n039697e10c84: Download complete\\n43bfd8262e45: Verifying Checksum\\n43bfd8262e45: Download complete\\nb6b8ce44d43b: Verifying Checksum\\nb6b8ce44d43b: Download complete\\n1fba209e6565: Verifying Checksum\\n1fba209e6565: Download complete\\nb3ad9472f087: Verifying Checksum\\nb3ad9472f087: Download complete\\n0fd8b2b70fed: Verifying Checksum\\n0fd8b2b70fed: Download complete\\nbe8ec4e48d7f: Pull complete\\n33b8b485aff0: Pull complete\\nd887158cc58c: Pull complete\\n05895bb28c18: Pull complete\\nbaf7ab26f516: Pull complete\\n181182e3c9cf: Pull complete\\nd584ef274e55: Pull complete\\nc445dda55407: Pull complete\\n699b75ff4717: Pull complete\\nb177109c9d16: Pull complete\\n59cea07bb66c: Pull complete\\nd54d011de0e3: Pull complete\\n9e568eb651a5: Pull complete\\nd624e6e7775d: Pull complete\\n039697e10c84: Pull complete\\ncf1f21b548a5: Pull complete\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.22.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice,uniform, randint\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy, MedianStoppingPolicy\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, randint, choice\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.01)\n",
    "another_early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "## Hyper Parameter Optimization\n",
    "hyperparameter_grid = RandomParameterSampling({\n",
    "    '--max_depth':choice(2, 3, 5, 10),\n",
    "    '--learning_rate':choice(0.05,0.1,0.15,0.20),\n",
    "    '--colsample_bytree':choice(0.3,0.5,0.7,0.9),\n",
    "    '--alpha':choice(10,20,30,40),\n",
    "    '--n_estimators':choice(100, 500, 900, 1100)\n",
    "    }\n",
    ")\n",
    "                \n",
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=hyperparameter_grid, \n",
    "                                     primary_metric_name='mean_squared_error',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                     policy=early_termination_policy,\n",
    "                                     max_total_runs=10,\n",
    "                                     max_concurrent_runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor HyperDrive runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(hyperdrive_run.get_status() == \"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your best run and save the model from that run.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_hyperdrive_model = best_run.register_model(\n",
    "    model_name=\"House_Price_Model\",\n",
    "    model_path='outputs/house_price_model.pkl',\n",
    "   \n",
    ")\n",
    "best_run.download_file(\"outputs/house_price_model.pkl\", \"outputs/house_price_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "#from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_config = AciWebservice.deploy_configuration(\n",
    "            cpu_cores=1,\n",
    "            memory_gb=4, \n",
    "            enable_app_insights=True,\n",
    "            auth_enabled=True,\n",
    "            tags={\"data\":\"house price regression\"},\n",
    "            description='house price regression Model',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(workspace=ws,\n",
    "                       name=\"house-price-ml-service\",\n",
    "                       models=[best_hyperdrive_model], \n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = service.get_logs()\n",
    "for line in logs.split('\\n'):\n",
    "     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print service state\n",
    "print(service.state)\n",
    "# print scoring URI\n",
    "print('scoring URI: ' + service.scoring_uri)\n",
    "# print Swagger URI\n",
    "print('Swagger URI: ' + service.swagger_uri)\n",
    "# retrieve authentication keys\n",
    "primary, secondary = service.get_keys()\n",
    "# print primary authenticaton key\n",
    "print('Primary Authentication Key: ' + primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the uri's in variables:\n",
    "scoring_uri = 'http://b7e34bc0-f1f3-4b47-8837-c46f3e8899af.southcentralus.azurecontainer.io/score'\n",
    "\n",
    "key = 'SEMOR6g83ld8yjaB5OV05dxuct8eillI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume the Endpoint and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #connect to dataset\n",
    "# #https://medium.com/analytics-vidhya/deploy-your-ml-models-using-5-easy-steps-with-azure-machine-learning-workspace-c1ca5b6aa284\n",
    "# dataset = Dataset.get_by_name(ws, name='<Name of dataset in AMLW>')\n",
    "# dataset = dataset.to_pandas_dataframe()\n",
    "\n",
    "# #package and run input data to model\n",
    "# #input data\n",
    "# input_data = dataset.to_json()\n",
    "\n",
    "# #run model\n",
    "# pred = service.run(input_data)\n",
    "# #Convert returned json back to a pandas dataframe\n",
    "# pred = pd.read_json(pred)\n",
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "dataset_test = Dataset.Tabular.from_delimited_files(path='https://raw.githubusercontent.com/ddgope/Udacity-Capstone-House-Price-Predication-Using-Azure-ML/master/testdata.csv')\n",
    "df_Test = dataset_test.to_pandas_dataframe()\n",
    "df_Test.drop(['Column1','SalePrice'],axis=1,inplace=True) \n",
    "#df_Test.head()\n",
    "#df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data\n",
    "input_data = df_Test.to_json(orient=\"table\",index=False)\n",
    "#print(input_data)\n",
    "input_data=json.dumps({\"data\": json.loads(input_data)[\"data\"]},indent=4)\n",
    "#run model\n",
    "pred = service.run(input_data)\n",
    "#Convert returned json back to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the result\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Test.to_json('./testdata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test requests:\n",
    "import json\n",
    "import requests\n",
    "\n",
    "scoring_uri = scoring_uri\n",
    "key = key\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = df_Test.to_json(orient=\"table\",index=False)\n",
    "#print(input_data)\n",
    "input_data=json.dumps({\"data\": json.loads(input_data)[\"data\"]},indent=4)\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)\n",
    "\n",
    "#load the returned prediction and read it into a pandas dataframe\n",
    "pred = json.loads(resp.text)\n",
    "pred = pd.read_json(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(pred)\n",
    "sub_df=pd.read_csv('https://raw.githubusercontent.com/ddgope/Udacity-Capstone-House-Price-Predication-Using-Azure-ML/master/sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
