{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.22.0\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turning diagnostics collection on. \n"
     ]
    }
   ],
   "source": [
    "from azureml.telemetry import set_diagnostics_collection\n",
    "\n",
    "set_diagnostics_collection(send_diagnostics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workspace name: quick-starts-ws-139721\n",
      "Azure region: southcentralus\n",
      "Subscription id: 9b72f9e6-56c5-4c16-991b-19c652994860\n",
      "Resource group: aml-quickstarts-139721\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.workspace import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print('Workspace name: ' + ws.name, \n",
    "      'Azure region: ' + ws.location, \n",
    "      'Subscription id: ' + ws.subscription_id, \n",
    "      'Resource group: ' + ws.resource_group, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "{'currentNodeCount': 0, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 0, 'preemptedNodeCount': 0}, 'allocationState': 'Steady', 'allocationStateTransitionTime': '2021-03-02T17:33:18.607000+00:00', 'errors': None, 'creationTime': '2021-03-02T17:11:16.631284+00:00', 'modifiedTime': '2021-03-02T17:11:31.985785+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"compute-cluster\"\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing compute target')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute target...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', \n",
    "                                                           max_nodes=4)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "# can poll for a minimum number of nodes and for a specific timeout. \n",
    "# if no min node count is provided it uses the scale settings for the cluster\n",
    "compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "project_folder = './capstone-project'\n",
    "os.makedirs(project_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./capstone-project/train.py'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('train.py', project_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "\n",
    "experiment_name = 'House_Price_Predication'\n",
    "experiment = Experiment(ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore,Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core.run import Run\n",
    "\n",
    "\n",
    "# subscription_id = '9b72f9e6-56c5-4c16-991b-19c652994860'\n",
    "# resource_group = 'aml-quickstarts-139721'\n",
    "# workspace_name = 'quick-starts-ws-139721'\n",
    "\n",
    "# workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
    "ws = Workspace.from_config()\n",
    "#ws\n",
    "\n",
    "# get the name of defult Datastore associated with the workspace.\n",
    "default_dsname = ws.get_default_datastore().name\n",
    "default_ds = ws.get_default_datastore()\n",
    "print('default Datastore = ', default_dsname)\n",
    "\n",
    "#Upload the files in default datastore\n",
    "default_ds.upload_files(files=['./house-price-train-data.csv']\n",
    "                        ,target_path='capstoneproject/'\n",
    "                        ,overwrite=True, show_progress=True)\n",
    "\n",
    "flower_data_ref = default_ds.path('capstoneproject').as_download('ex_capstoneproject')\n",
    "print('reference_path = ',flower_data_ref)\n",
    "\n",
    "\n",
    "# Creating tabular dataset from files in datastore.\n",
    "tab_dataset = Dataset.Tabular.from_delimited_files(path=(default_ds,'/capstoneproject/*.csv'))\n",
    "#tab_dataset.take(10).to_pandas_dataframe()\n",
    "\n",
    "# register tabular dataset in Workspace\n",
    "tab_dataset = tab_dataset.register(workspace=ws, \n",
    "                                   name='house price train data', \n",
    "                                   description='Kaggle house price Dataset in tabular format', \n",
    "                                   tags={'format':'CSV'}, create_new_version=True)\n",
    "\n",
    "# Get the data Using Dataset name which is registered.\n",
    "dataset = Dataset.get_by_name(ws, name='house price train data')\n",
    "ds=dataset.to_pandas_dataframe()\n",
    "ds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an environment\n",
    "Define a conda environment YAML file with your training script dependencies and create an Azure ML environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting conda_dependencies.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile conda_dependencies.yml\n",
    "\n",
    "# Conda environment specification. The dependencies defined in this file will\n",
    "# be automatically provisioned for runs with userManagedDependencies=False.\n",
    "\n",
    "# Details about the Conda environment file format:\n",
    "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
    "\n",
    "name: project_environment\n",
    "dependencies:\n",
    "  # The python interpreter version.\n",
    "  # Currently Azure ML only supports 3.5.2 and later.\n",
    "- python=3.6.2\n",
    "\n",
    "- pip:\n",
    "  - azureml-train-automl-runtime==1.21.0\n",
    "  - inference-schema\n",
    "  - azureml-interpret==1.21.0\n",
    "  - azureml-defaults==1.21.0\n",
    "- numpy>=1.16.0,<1.19.0\n",
    "- pandas==0.25.1\n",
    "- scikit-learn==0.22.1\n",
    "- xgboost<=1.3.3\n",
    "- psutil>=5.2.2,<6.0.0\n",
    "channels:\n",
    "- anaconda\n",
    "- conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "\n",
    "env = Environment.from_conda_specification(name = 'capstone-project-env', file_path = './conda_dependencies.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "\n",
    "src = ScriptRunConfig(source_directory=project_folder,\n",
    "                      script='train.py',\n",
    "                      arguments=['--max_depth', '5'\n",
    "                                 ,'--learning_rate',  0.1\n",
    "                                 ,'--colsample_bytree',0.3\n",
    "                                 ,'--alpha',10\n",
    "                                 ,'--n_estimators',10],\n",
    "                      compute_target=compute_target,\n",
    "                      environment=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = experiment.submit(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor The Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c2f4754b3a4859a12175e3e7db824a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 's…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Failed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/House_Price_Predication/runs/House_Price_Predication_1614707162_4b74bf25?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-139721/workspaces/quick-starts-ws-139721\", \"run_id\": \"House_Price_Predication_1614707162_4b74bf25\", \"run_properties\": {\"run_id\": \"House_Price_Predication_1614707162_4b74bf25\", \"created_utc\": \"2021-03-02T17:46:05.292234Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"amlcompute\", \"ContentSnapshotId\": \"e8d326c7-f0fd-4b13-adca-699a2bb3fdef\", \"ProcessInfoFile\": \"azureml-logs/process_info.json\", \"ProcessStatusFile\": \"azureml-logs/process_status.json\"}, \"tags\": {\"_aml_system_ComputeTargetStatus\": \"{\\\"AllocationState\\\":\\\"steady\\\",\\\"PreparingNodeCount\\\":0,\\\"RunningNodeCount\\\":0,\\\"CurrentNodeCount\\\":0}\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2021-03-02T17:54:10.517386Z\", \"status\": \"Failed\", \"log_files\": {\"azureml-logs/55_azureml-execution-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/55_azureml-execution-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt?sv=2019-02-02&sr=b&sig=yqHJQ7tWUk75LQvEzAnae7mBjOSvuY3MAgK5%2BY%2FTiGI%3D&st=2021-03-02T18%3A43%3A56Z&se=2021-03-03T02%3A53%3A56Z&sp=r\", \"azureml-logs/65_job_prep-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/65_job_prep-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt?sv=2019-02-02&sr=b&sig=Yj4i1c8lM86ipa1YhbO734bAopevG%2BWq52nru1L8O%2BU%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=dunvBU7B6bTUaEA4JdMgDFmb7jfdvwQsfimv0b3eTv4%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"azureml-logs/75_job_post-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/75_job_post-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt?sv=2019-02-02&sr=b&sig=xo%2BTRQVbm4XsnIYBfE7Ulgg4knNs6mFzN0IpXmEgWhk%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"azureml-logs/process_info.json\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=t3KY9ISkYvTh3YqCZVtG9OdR5%2Fa9hE4ntslme%2BunP%2BI%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"azureml-logs/process_status.json\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=m0lQAy73uwyI%2FAtJJQVehyHlNRrwy56V%2FQDr5CkTEMI%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"logs/azureml/101_azureml.log\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/logs/azureml/101_azureml.log?sv=2019-02-02&sr=b&sig=heiUdunU0VdcaRR9mpF5T2E5uFmz9Waxw2pXpfB3yCE%3D&st=2021-03-02T18%3A43%3A56Z&se=2021-03-03T02%3A53%3A56Z&sp=r\", \"logs/azureml/job_prep_azureml.log\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=%2BBFt7Xzv93h1PdBZovLBhYVL0PE%2BKEtJ210g4s1xJAk%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\", \"logs/azureml/job_release_azureml.log\": \"https://mlstrg139721.blob.core.windows.net/azureml/ExperimentRun/dcid.House_Price_Predication_1614707162_4b74bf25/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=20zzeQDhZdDP4kGx3PdmfLDWNcbnsF3v3zfzuVsiwVs%3D&st=2021-03-02T18%3A43%3A57Z&se=2021-03-03T02%3A53%3A57Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/process_info.json\", \"azureml-logs/process_status.json\", \"logs/azureml/job_prep_azureml.log\", \"logs/azureml/job_release_azureml.log\"], [\"azureml-logs/55_azureml-execution-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\"], [\"azureml-logs/65_job_prep-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"azureml-logs/75_job_post-tvmps_d702a0209add2cc1b11ed459af6d1559c080dd85fd3e7e52f4aa545eb3289470_d.txt\"], [\"logs/azureml/101_azureml.log\"]], \"run_duration\": \"0:08:05\", \"run_number\": \"12\", \"run_queued_details\": {\"status\": \"Failed\", \"details\": null}}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [], \"run_logs\": \"2021-03-02 17:53:36,483|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': True, 'only_in_process_features': True, 'skip_track_logs_dir': True}, track_folders: None, deny_list: None, directories_to_watch: []\\n2021-03-02 17:53:36,484|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: batchai\\n2021-03-02 17:53:36,492|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Failed to import pyspark with error: No module named 'pyspark'\\n2021-03-02 17:53:36,492|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2021-03-02 17:53:39,381|azureml.core.run|DEBUG|Adding new factory <function AutoMLRun._from_run_dto at 0x7f9d4dc6f8c8> for run source automl\\n2021-03-02 17:53:39,391|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7f9d69079598> for run source azureml.scriptrun\\n2021-03-02 17:53:39,395|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:39,416|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2021-03-02 17:53:39,416|azureml.core.authentication|DEBUG|Time to expire 1813945.583534 seconds\\n2021-03-02 17:53:39,416|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2021-03-02 17:53:39,417|azureml.core.authentication|DEBUG|Time to expire 1813945.582234 seconds\\n2021-03-02 17:53:39,418|azureml.core.authentication|DEBUG|Time to expire 1813945.58119 seconds\\n2021-03-02 17:53:39,418|azureml._restclient.clientbase|DEBUG|ClientBase: Calling get with url None\\n2021-03-02 17:53:39,419|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-02 17:53:39,419|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2021-03-02 17:53:39,453|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,454|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,455|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,458|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,458|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,458|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,459|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,460|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,460|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,461|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,461|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,461|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,461|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,462|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,462|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,470|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,470|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,470|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://southcentralus.experiments.azureml.net.\\n2021-03-02 17:53:39,551|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-02 17:53:39,561|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-02 17:53:39,565|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-02 17:53:39,576|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-02 17:53:39,575|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2021-03-02 17:53:39,580|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2021-03-02 17:53:39,643|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:39,643|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'e8d326c7-f0fd-4b13-adca-699a2bb3fdef', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-02 17:53:39,644|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-02 17:53:39,663|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:39,664|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'e8d326c7-f0fd-4b13-adca-699a2bb3fdef', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-02 17:53:39,664|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-02 17:53:40,045|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:40,046|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'amlcompute', 'ContentSnapshotId': 'e8d326c7-f0fd-4b13-adca-699a2bb3fdef', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}\\n2021-03-02 17:53:40,046|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2021-03-02 17:53:40,047|azureml|WARNING|Could not import azureml.mlflow or azureml.contrib.mlflow mlflow APIs will not run against AzureML services.  Add azureml-mlflow as a conda dependency for the run if this behavior is desired\\n2021-03-02 17:53:40,047|azureml.WorkerPool|DEBUG|[START]\\n2021-03-02 17:53:40,047|azureml.SendRunKillSignal|DEBUG|[START]\\n2021-03-02 17:53:40,047|azureml.RunStatusContext|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunContextManager.RunStatusContext|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml.MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2021-03-02 17:53:40,048|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25\\n2021-03-02 17:53:40,048|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-02 17:53:40,048|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25\\n2021-03-02 17:53:40,293|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2021-03-02 17:53:40,293|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25\\n2021-03-02 17:53:40,293|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25 to /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25\\n2021-03-02 17:53:40,294|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /mnt/batch/tasks/shared/LS_root/jobs/quick-starts-ws-139721/azureml/house_price_predication_1614707162_4b74bf25/mounts/workspaceblobstore/azureml/House_Price_Predication_1614707162_4b74bf25\\n2021-03-02 17:53:40,294|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2021-03-02 17:53:40,294|azureml.WorkingDirectoryCM|ERROR|<class 'FileNotFoundError'>: [Errno 2] File b'house-price-train-data.csv' does not exist: b'house-price-train-data.csv'\\n<traceback object at 0x7f9d3b291448>\\n2021-03-02 17:53:40,294|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2021-03-02 17:53:40,294|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,294|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,294|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,295|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 120 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 120 seconds on tasks: [].\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,296|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-02 17:53:40,297|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-02 17:53:40,350|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:40,351|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,351|azureml.MetricsClient|ERROR|<class 'FileNotFoundError'>: [Errno 2] File b'house-price-train-data.csv' does not exist: b'house-price-train-data.csv'\\n<traceback object at 0x7f9d3b291448>\\n2021-03-02 17:53:40,351|azureml.MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,351|azureml.RunStatusContext|ERROR|<class 'FileNotFoundError'>: [Errno 2] File b'house-price-train-data.csv' does not exist: b'house-price-train-data.csv'\\n<traceback object at 0x7f9d3b291448>\\n2021-03-02 17:53:40,351|azureml.RunStatusContext|DEBUG|[STOP]\\n2021-03-02 17:53:40,351|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,352|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-02 17:53:40,353|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,354|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,354|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-02 17:53:40,354|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-02 17:53:40,406|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.PostMetricsBatchDaemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,407|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,408|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-02 17:53:40,408|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,408|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2021-03-02 17:53:40,408|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-02 17:53:40,409|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch|DEBUG|\\n2021-03-02 17:53:40,461|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatch.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[START]\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|flush timeout 900.0 is different from task queue timeout 120, using flush timeout\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|Waiting 900.0 seconds on tasks: [].\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.WaitFlushSource:MetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.FlushingMetricsClient|DEBUG|[STOP]\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[START]\\n2021-03-02 17:53:40,462|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling wait_on_ingest with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/metricsingest/wait\\n2021-03-02 17:53:40,533|azureml._SubmittedRun#House_Price_Predication_1614707162_4b74bf25.RunHistoryFacade.MetricsClient.wait_on_ingest-async:False|DEBUG|[STOP]\\n2021-03-02 17:53:40,533|azureml.SendRunKillSignal|ERROR|<class 'FileNotFoundError'>: [Errno 2] File b'house-price-train-data.csv' does not exist: b'house-price-train-data.csv'\\n<traceback object at 0x7f9d3b291448>\\n2021-03-02 17:53:40,534|azureml.SendRunKillSignal|DEBUG|[STOP]\\n2021-03-02 17:53:40,534|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[START]\\n2021-03-02 17:53:40,534|azureml.HistoryTrackingWorkerPool.WorkerPoolShutdown|DEBUG|[STOP]\\n2021-03-02 17:53:40,534|azureml.WorkerPool|ERROR|<class 'FileNotFoundError'>: [Errno 2] File b'house-price-train-data.csv' does not exist: b'house-price-train-data.csv'\\n<traceback object at 0x7f9d3b291448>\\n2021-03-02 17:53:40,534|azureml.WorkerPool|DEBUG|[STOP]\\n\\nError occurred: AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": true, \"log_level\": \"INFO\", \"sdk_version\": \"1.22.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "RunDetails(run).show()\n",
    "#run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
    "from azureml.train.hyperdrive.sampling import RandomParameterSampling\n",
    "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
    "from azureml.train.hyperdrive.parameter_expressions import choice,uniform, randint\n",
    "from azureml.train.hyperdrive.policy import BanditPolicy, MedianStoppingPolicy\n",
    "from azureml.train.hyperdrive.parameter_expressions import uniform, randint, choice\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score\n",
    "\n",
    "early_termination_policy = BanditPolicy(slack_factor=0.01)\n",
    "another_early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=5)\n",
    "\n",
    "## Hyper Parameter Optimization\n",
    "hyperparameter_grid = RandomParameterSampling({\n",
    "    '--max_depth':choice(2, 3, 5, 10),\n",
    "    '--learning_rate':choice(0.05,0.1,0.15,0.20),\n",
    "    '--colsample_bytree':choice(0.3,0.5,0.7,0.9),\n",
    "    '--alpha':choice(10,20,30,40),\n",
    "    '--n_estimators':choice(100, 500, 900, 1100)\n",
    "    }\n",
    ")\n",
    "                \n",
    "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
    "                                     hyperparameter_sampling=hyperparameter_grid, \n",
    "                                     primary_metric_name='mean_squared_error',\n",
    "                                     primary_metric_goal=PrimaryMetricGoal.MINIMIZE,\n",
    "                                     policy=early_termination_policy,\n",
    "                                     max_total_runs=10,\n",
    "                                     max_concurrent_runs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start the HyperDrive run\n",
    "hyperdrive_run = experiment.submit(hyperdrive_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor HyperDrive runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(hyperdrive_run.get_status() == \"Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperdrive_run.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find and register best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your best run and save the model from that run.\n",
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['arguments']\n",
    "best_run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "best_hyperdrive_model = best_run.register_model(\n",
    "    model_name=\"House_Price_Model\",\n",
    "    model_path='outputs/house_price_model.pkl',\n",
    "   \n",
    ")\n",
    "best_run.download_file(\"outputs/house_price_model.pkl\", \"outputs/house_price_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.environment import Environment\n",
    "#from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aci_config = AciWebservice.deploy_configuration(\n",
    "            cpu_cores=1,\n",
    "            memory_gb=4, \n",
    "            enable_app_insights=True,\n",
    "            auth_enabled=True,\n",
    "            tags={\"data\":\"house price regression\"},\n",
    "            description='house price regression Model',\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = InferenceConfig(entry_script='score.py', environment=env)\n",
    "inference_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(workspace=ws,\n",
    "                       name=\"house-price-ml-service\",\n",
    "                       models=[best_hyperdrive_model], \n",
    "                       inference_config=inference_config,\n",
    "                       deployment_config=aci_config,\n",
    "                       overwrite=True)\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = service.get_logs()\n",
    "for line in logs.split('\\n'):\n",
    "     print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print service state\n",
    "print(service.state)\n",
    "# print scoring URI\n",
    "print('scoring URI: ' + service.scoring_uri)\n",
    "# print Swagger URI\n",
    "print('Swagger URI: ' + service.swagger_uri)\n",
    "# retrieve authentication keys\n",
    "primary, secondary = service.get_keys()\n",
    "# print primary authenticaton key\n",
    "print('Primary Authentication Key: ' + primary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store the uri's in variables:\n",
    "scoring_uri = 'http://b7e34bc0-f1f3-4b47-8837-c46f3e8899af.southcentralus.azurecontainer.io/score'\n",
    "\n",
    "key = 'SEMOR6g83ld8yjaB5OV05dxuct8eillI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consume the Endpoint and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #connect to dataset\n",
    "# #https://medium.com/analytics-vidhya/deploy-your-ml-models-using-5-easy-steps-with-azure-machine-learning-workspace-c1ca5b6aa284\n",
    "# dataset = Dataset.get_by_name(ws, name='<Name of dataset in AMLW>')\n",
    "# dataset = dataset.to_pandas_dataframe()\n",
    "\n",
    "# #package and run input data to model\n",
    "# #input data\n",
    "# input_data = dataset.to_json()\n",
    "\n",
    "# #run model\n",
    "# pred = service.run(input_data)\n",
    "# #Convert returned json back to a pandas dataframe\n",
    "# pred = pd.read_json(pred)\n",
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "dataset_test = Dataset.Tabular.from_delimited_files(path='https://raw.githubusercontent.com/ddgope/Udacity-Capstone-House-Price-Predication-Using-Azure-ML/master/testdata.csv')\n",
    "df_Test = dataset_test.to_pandas_dataframe()\n",
    "df_Test.drop(['Column1','SalePrice'],axis=1,inplace=True) \n",
    "#df_Test.head()\n",
    "#df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input data\n",
    "input_data = df_Test.to_json(orient=\"table\",index=False)\n",
    "#print(input_data)\n",
    "input_data=json.dumps({\"data\": json.loads(input_data)[\"data\"]},indent=4)\n",
    "#run model\n",
    "pred = service.run(input_data)\n",
    "#Convert returned json back to a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the result\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Test.to_json('./testdata.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's test requests:\n",
    "import json\n",
    "import requests\n",
    "\n",
    "scoring_uri = scoring_uri\n",
    "key = key\n",
    "\n",
    "headers = {'Content-Type':'application/json'}\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "# Convert to JSON string\n",
    "input_data = df_Test.to_json(orient=\"table\",index=False)\n",
    "#print(input_data)\n",
    "input_data=json.dumps({\"data\": json.loads(input_data)[\"data\"]},indent=4)\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.text)\n",
    "\n",
    "#load the returned prediction and read it into a pandas dataframe\n",
    "pred = json.loads(resp.text)\n",
    "pred = pd.read_json(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(pred)\n",
    "sub_df=pd.read_csv('https://raw.githubusercontent.com/ddgope/Udacity-Capstone-House-Price-Predication-Using-Azure-ML/master/sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
